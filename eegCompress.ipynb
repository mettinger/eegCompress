{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45693/4244858251.py:10: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget \n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "#mne.datasets.sample.data_path()\n",
    "\n",
    "import torch\n",
    "import eegCompressModels\n",
    "import imp\n",
    "imp.reload(eegCompressModels)\n",
    "\n",
    "import neptune\n",
    "from neptune_pytorch import NeptuneLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageCompare(start, channel = 0, plotOption=\"both\"):\n",
    "\n",
    "    original = data[channel,start:start + numSampleInput]\n",
    "\n",
    "    modelInput = np.reshape(data[:, start:start + numSampleInput], (inSize, -1), order='F').astype('float32').flatten()\n",
    "    encoded = model.encoder(torch.tensor(modelInput))\n",
    "    decoded = np.reshape(model.decoder(encoded).detach().numpy(), (nChannel, numSampleInput),order=\"C\")[channel, start:start + numSampleInput]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    if plotOption == \"both\":\n",
    "        plt.plot(original, label='original')\n",
    "        plt.plot(decoded, label='decoded')\n",
    "        plt.legend()\n",
    "    elif plotOption == \"orig\":\n",
    "        plt.plot(original)\n",
    "        plt.title('original')\n",
    "    else: \n",
    "        plt.plot(decoded)\n",
    "        plt.title('decoded')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /teamspace/uploads/ExampleLTMFiles/SVD001.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45693/3455569217.py:2: RuntimeWarning: Omitted 9 annotation(s) that were outside data range.\n",
      "  raw = mne.io.read_raw_edf('/teamspace/uploads/ExampleLTMFiles/SVD001.edf')\n"
     ]
    }
   ],
   "source": [
    "#raw = mne.io.read_raw_fif('./mne_data/MNE-sample-data/MEG/sample/sample_audvis_raw.fif')\n",
    "raw = mne.io.read_raw_edf('/teamspace/uploads/ExampleLTMFiles/SVD001.edf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RawEDF | SVD001.edf, 46 x 1276416 (4986.0 s), ~48 KiB, data not loaded>\n",
      "<Info | 8 non-empty values\n",
      " bads: []\n",
      " ch_names: Fp1, F7, T7, P7, O1, F3, C3, P3, A1, Fz, Cz, Fp2, F8, T8, P8, ...\n",
      " chs: 46 EEG\n",
      " custom_ref_applied: False\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 128.0 Hz\n",
      " meas_date: 2001-01-01 04:46:55 UTC\n",
      " nchan: 46\n",
      " projs: []\n",
      " sfreq: 256.0 Hz\n",
      " subject_info: <subject_info | his_id: SVD001>\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "print(raw)\n",
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 1276416)\n"
     ]
    }
   ],
   "source": [
    "chanList = range(0,19)\n",
    "nChannel = len(chanList)\n",
    "\n",
    "data = raw.get_data()[chanList] #eeg channels\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nChannel):\n",
    "    data[i,:] = (data[i,:] - np.mean(data[i,:])) / np.std(data[i,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata = np.random.random((1,100000))\\ndata = data - np.mean(data)\\ndata = data/np.std(data)\\nnChannel = data.shape[0]\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data = np.random.random((1,100000))\n",
    "data = data - np.mean(data)\n",
    "data = data/np.std(data)\n",
    "nChannel = data.shape[0]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 95\n",
      "AE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=95, out_features=95, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=95, out_features=95, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Set in/out parameters\n",
    "numSampleInput = 5\n",
    "outSizeRatio = 1.0\n",
    "inSize = nChannel * numSampleInput\n",
    "outSize = int(inSize * outSizeRatio)\n",
    "print(inSize, outSize)\n",
    "\n",
    "# Construct the DataLoader\n",
    "dataset = eegCompressModels.CustomDataset(data, numSampleInput)\n",
    "batch_size = 32\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Make the model\n",
    "encoderSizeList = [inSize, outSize]\n",
    "decoderSizeList = [outSize, inSize]\n",
    "encoderActivationList = [False]\n",
    "decoderActivationList = [False]\n",
    "\n",
    "model = eegCompressModels.AE(encoderSizeList, decoderSizeList, encoderActivationList, decoderActivationList)\n",
    "print(model)\n",
    "loss_function = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: By default, these monitoring options are disabled in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', 'capture_hardware_metrics'. You can set them to 'True' when initializing the run and the monitoring will continue until you call run.stop() or the kernel stops. NOTE: To track the source files, pass their paths to the 'source_code' argument. For help, see: https://docs.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/jettinger35/eegCompress/e/EEG-92\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "    project=\"jettinger35/eegCompress\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzMjFlMzY2MS1iOWZiLTRmZWEtOGMwNy0zOTVkMTljOGVjYTMifQ==\",\n",
    ")\n",
    "\n",
    "npt_logger = NeptuneLogger(\n",
    "    run=run,\n",
    "    model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.0)\n",
    "#optimizer = torch.optim.Adam(model.parameters())#, lr = 1e-1, weight_decay = 1e-8)\n",
    "\n",
    "totalEpoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "startPlot = 0\n",
    "\n",
    "outputs = []\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\tfor (image, _) in loader:\n",
    "\t\t# Output of Autoencoder\n",
    "\t\treconstructed = model(image.to(torch.float32))\n",
    "\t\t\n",
    "\t\t# Calculating the loss function\n",
    "\t\tloss = loss_function(reconstructed, image)\n",
    "\t\t\n",
    "\t\t# The gradients are set to zero,\n",
    "\t\t# the gradient is computed and stored.\n",
    "\t\t# .step() performs parameter update\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\n",
    "\t\t# Storing the losses in a list for plotting\n",
    "\t\tlosses.append(loss)\n",
    "\t\toutputs.append((epochs, image, reconstructed))\n",
    "\t\trun[npt_logger.base_namespace][\"train/log_loss\"].append(np.log(loss.item()))\n",
    "\n",
    "\tfig = imageCompare(startPlot)\n",
    "\tplt.title(\"Total Epoch: \" + str(totalEpoch))\n",
    "\trun[\"fig\"].append(fig)\n",
    "\tplt.close()\n",
    "    totalEpoch = totalEpoch + 1\n",
    "\n",
    "torch.save(model.state_dict(), 'savedModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print((name, param.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startPlot = 0\n",
    "plt.show(imageCompare(startPlot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
